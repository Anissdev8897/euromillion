#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module de Fusion Multi-Mod√®les Dynamique
Ce module fusionne intelligemment les pr√©dictions de tous les mod√®les avec:
- Stacking avanc√© avec m√©ta-mod√®le
- Blending pond√©r√© dynamique
- Voting intelligent avec poids adaptatifs
- Auto-ajustement des poids apr√®s chaque tirage
"""

import os
import sys
import logging
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from pathlib import Path
from datetime import datetime
import json
import pickle
import traceback
from collections import defaultdict

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("MetaModelFusion")

# Imports ML
try:
    from sklearn.ensemble import StackingClassifier, VotingClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import cross_val_score
    import xgboost as xgb
    import lightgbm as lgb
    SKLEARN_AVAILABLE = True
    logger.info("‚úÖ Biblioth√®ques ML disponibles")
except ImportError as e:
    SKLEARN_AVAILABLE = False
    logger.error(f"‚ùå Erreur import ML: {e}")


class MetaModelFusion:
    """
    Classe pour la fusion intelligente de multiples mod√®les de pr√©diction.
    Supporte stacking, blending, et voting avec ajustement dynamique des poids.
    """
    
    def __init__(
        self,
        fusion_method: str = "stacking",
        meta_model_type: str = "xgboost",
        auto_adjust: bool = True,
        config_file: Optional[str] = None
    ):
        """
        Initialise le syst√®me de fusion multi-mod√®les.
        
        Args:
            fusion_method: M√©thode de fusion ("stacking", "blending", "voting")
            meta_model_type: Type de m√©ta-mod√®le ("xgboost", "lightgbm", "logistic")
            auto_adjust: Activer l'ajustement automatique des poids
            config_file: Fichier de configuration YAML/JSON
        """
        self.fusion_method = fusion_method
        self.meta_model_type = meta_model_type
        self.auto_adjust = auto_adjust
        
        # Mod√®les et leurs poids
        self.models = {}
        self.model_weights = {}
        self.model_scores = defaultdict(list)
        
        # M√©ta-mod√®le
        self.meta_model = None
        self.scaler = StandardScaler()
        
        # Historique des performances
        self.performance_history = []
        
        # Configuration
        self.config = self._load_config(config_file) if config_file else {}
        
        logger.info(f"‚úÖ MetaModelFusion initialis√©: {fusion_method} + {meta_model_type}")
    
    def _load_config(self, config_file: str) -> Dict:
        """Charge la configuration depuis un fichier."""
        try:
            config_path = Path(config_file)
            if not config_path.exists():
                logger.warning(f"Fichier config non trouv√©: {config_file}")
                return {}
            
            if config_file.endswith('.json'):
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            elif config_file.endswith('.yaml') or config_file.endswith('.yml'):
                import yaml
                with open(config_file, 'r', encoding='utf-8') as f:
                    return yaml.safe_load(f)
            else:
                logger.error(f"Format config non support√©: {config_file}")
                return {}
        except Exception as e:
            logger.error(f"Erreur chargement config: {e}")
            return {}
    
    def register_model(
        self,
        model_name: str,
        model: Any,
        initial_weight: float = 1.0,
        enabled: bool = True
    ):
        """
        Enregistre un mod√®le dans le syst√®me de fusion.
        
        Args:
            model_name: Nom unique du mod√®le
            model: Instance du mod√®le (doit avoir predict/predict_proba)
            initial_weight: Poids initial (d√©faut: 1.0)
            enabled: Activer le mod√®le
        """
        if not enabled:
            logger.info(f"‚è≠Ô∏è Mod√®le {model_name} d√©sactiv√©")
            return
        
        self.models[model_name] = model
        self.model_weights[model_name] = initial_weight
        logger.info(f"‚úÖ Mod√®le enregistr√©: {model_name} (poids: {initial_weight})")
    
    def _create_meta_model(self):
        """Cr√©e le m√©ta-mod√®le selon la configuration."""
        if self.meta_model_type == "xgboost":
            self.meta_model = xgb.XGBClassifier(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42
            )
        elif self.meta_model_type == "lightgbm":
            self.meta_model = lgb.LGBMClassifier(
                n_estimators=100,
                max_depth=5,
                learning_rate=0.1,
                random_state=42
            )
        elif self.meta_model_type == "logistic":
            self.meta_model = LogisticRegression(
                max_iter=1000,
                random_state=42
            )
        else:
            logger.warning(f"Type m√©ta-mod√®le inconnu: {self.meta_model_type}, utilisation logistic")
            self.meta_model = LogisticRegression(max_iter=1000, random_state=42)
        
        logger.info(f"‚úÖ M√©ta-mod√®le cr√©√©: {self.meta_model_type}")
    
    def fit(self, X: np.ndarray, y: np.ndarray):
        """
        Entra√Æne le syst√®me de fusion sur les donn√©es.
        
        Args:
            X: Features d'entra√Ænement
            y: Labels d'entra√Ænement
        """
        if not self.models:
            logger.error("‚ùå Aucun mod√®le enregistr√©")
            return
        
        logger.info(f"üîß Entra√Ænement du syst√®me de fusion ({len(self.models)} mod√®les)...")
        
        try:
            if self.fusion_method == "stacking":
                self._fit_stacking(X, y)
            elif self.fusion_method == "blending":
                self._fit_blending(X, y)
            elif self.fusion_method == "voting":
                self._fit_voting(X, y)
            else:
                logger.error(f"M√©thode de fusion inconnue: {self.fusion_method}")
                return
            
            logger.info("‚úÖ Entra√Ænement du syst√®me de fusion termin√©")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'entra√Ænement: {e}")
            logger.debug(traceback.format_exc())
    
    def _fit_stacking(self, X: np.ndarray, y: np.ndarray):
        """Entra√Æne avec la m√©thode stacking."""
        # Cr√©er le m√©ta-mod√®le
        self._create_meta_model()
        
        # Collecter les pr√©dictions de tous les mod√®les
        meta_features = []
        
        for model_name, model in self.models.items():
            try:
                # Entra√Æner le mod√®le de base
                logger.info(f"  Entra√Ænement de {model_name}...")
                model.fit(X, y)
                
                # Obtenir les pr√©dictions (probabilities si disponible)
                if hasattr(model, 'predict_proba'):
                    preds = model.predict_proba(X)
                else:
                    preds = model.predict(X).reshape(-1, 1)
                
                meta_features.append(preds)
                logger.info(f"  ‚úÖ {model_name} entra√Æn√©")
            except Exception as e:
                logger.error(f"  ‚ùå Erreur avec {model_name}: {e}")
        
        # Concat√©ner les features pour le m√©ta-mod√®le
        if meta_features:
            X_meta = np.hstack(meta_features)
            
            # Normaliser
            X_meta = self.scaler.fit_transform(X_meta)
            
            # Entra√Æner le m√©ta-mod√®le
            logger.info("  Entra√Ænement du m√©ta-mod√®le...")
            self.meta_model.fit(X_meta, y)
            logger.info("  ‚úÖ M√©ta-mod√®le entra√Æn√©")
    
    def _fit_blending(self, X: np.ndarray, y: np.ndarray):
        """Entra√Æne avec la m√©thode blending (similaire √† stacking mais plus simple)."""
        # Pour blending, on entra√Æne simplement tous les mod√®les
        for model_name, model in self.models.items():
            try:
                logger.info(f"  Entra√Ænement de {model_name}...")
                model.fit(X, y)
                logger.info(f"  ‚úÖ {model_name} entra√Æn√©")
            except Exception as e:
                logger.error(f"  ‚ùå Erreur avec {model_name}: {e}")
    
    def _fit_voting(self, X: np.ndarray, y: np.ndarray):
        """Entra√Æne avec la m√©thode voting."""
        # Entra√Æner tous les mod√®les
        for model_name, model in self.models.items():
            try:
                logger.info(f"  Entra√Ænement de {model_name}...")
                model.fit(X, y)
                logger.info(f"  ‚úÖ {model_name} entra√Æn√©")
            except Exception as e:
                logger.error(f"  ‚ùå Erreur avec {model_name}: {e}")
    
    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Fait une pr√©diction en fusionnant tous les mod√®les.
        
        Args:
            X: Features pour la pr√©diction
            
        Returns:
            Pr√©dictions fusionn√©es
        """
        if not self.models:
            logger.error("‚ùå Aucun mod√®le disponible")
            return np.array([])
        
        try:
            if self.fusion_method == "stacking":
                return self._predict_stacking(X)
            elif self.fusion_method == "blending":
                return self._predict_blending(X)
            elif self.fusion_method == "voting":
                return self._predict_voting(X)
            else:
                logger.error(f"M√©thode de fusion inconnue: {self.fusion_method}")
                return np.array([])
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la pr√©diction: {e}")
            logger.debug(traceback.format_exc())
            return np.array([])
    
    def _predict_stacking(self, X: np.ndarray) -> np.ndarray:
        """Pr√©diction avec stacking."""
        if self.meta_model is None:
            logger.error("‚ùå M√©ta-mod√®le non entra√Æn√©")
            return np.array([])
        
        # Collecter les pr√©dictions de tous les mod√®les
        meta_features = []
        
        for model_name, model in self.models.items():
            try:
                if hasattr(model, 'predict_proba'):
                    preds = model.predict_proba(X)
                else:
                    preds = model.predict(X).reshape(-1, 1)
                meta_features.append(preds)
            except Exception as e:
                logger.error(f"Erreur pr√©diction {model_name}: {e}")
        
        if not meta_features:
            return np.array([])
        
        # Concat√©ner et normaliser
        X_meta = np.hstack(meta_features)
        X_meta = self.scaler.transform(X_meta)
        
        # Pr√©diction finale avec m√©ta-mod√®le
        return self.meta_model.predict(X_meta)
    
    def _predict_blending(self, X: np.ndarray) -> np.ndarray:
        """Pr√©diction avec blending (moyenne pond√©r√©e)."""
        predictions = []
        weights = []
        
        for model_name, model in self.models.items():
            try:
                pred = model.predict(X)
                predictions.append(pred)
                weights.append(self.model_weights.get(model_name, 1.0))
            except Exception as e:
                logger.error(f"Erreur pr√©diction {model_name}: {e}")
        
        if not predictions:
            return np.array([])
        
        # Normaliser les poids
        weights = np.array(weights)
        weights = weights / weights.sum()
        
        # Moyenne pond√©r√©e
        predictions = np.array(predictions)
        weighted_pred = np.average(predictions, axis=0, weights=weights)
        
        # Arrondir pour classification
        return np.round(weighted_pred).astype(int)
    
    def _predict_voting(self, X: np.ndarray) -> np.ndarray:
        """Pr√©diction avec voting (vote majoritaire pond√©r√©)."""
        all_predictions = []
        weights = []
        
        for model_name, model in self.models.items():
            try:
                pred = model.predict(X)
                all_predictions.append(pred)
                weights.append(self.model_weights.get(model_name, 1.0))
            except Exception as e:
                logger.error(f"Erreur pr√©diction {model_name}: {e}")
        
        if not all_predictions:
            return np.array([])
        
        # Vote pond√©r√©
        all_predictions = np.array(all_predictions)
        weights = np.array(weights)
        
        # Pour chaque √©chantillon, compter les votes pond√©r√©s
        final_predictions = []
        for i in range(all_predictions.shape[1]):
            votes = all_predictions[:, i]
            # Vote majoritaire pond√©r√©
            unique_votes = np.unique(votes)
            vote_counts = {}
            for vote in unique_votes:
                mask = votes == vote
                vote_counts[vote] = np.sum(weights[mask])
            
            # S√©lectionner le vote avec le plus grand poids
            winner = max(vote_counts.items(), key=lambda x: x[1])[0]
            final_predictions.append(winner)
        
        return np.array(final_predictions)
    
    def predict_numbers_and_stars(
        self,
        X: np.ndarray,
        num_numbers: int = 5,
        num_stars: int = 2,
        max_number: int = 50,
        max_star: int = 12
    ) -> Dict[str, List[int]]:
        """
        Pr√©dit des num√©ros et √©toiles EuroMillions.
        
        Args:
            X: Features pour la pr√©diction
            num_numbers: Nombre de num√©ros √† pr√©dire (5)
            num_stars: Nombre d'√©toiles √† pr√©dire (2)
            max_number: Num√©ro maximum (50)
            max_star: √âtoile maximum (12)
            
        Returns:
            Dict avec 'numbers' et 'stars'
        """
        try:
            # Obtenir les scores de probabilit√© pour chaque num√©ro
            number_scores = self._get_number_scores(X, max_number)
            star_scores = self._get_star_scores(X, max_star)
            
            # S√©lectionner les top num√©ros et √©toiles
            top_numbers = sorted(
                range(1, max_number + 1),
                key=lambda x: number_scores.get(x, 0),
                reverse=True
            )[:num_numbers]
            
            top_stars = sorted(
                range(1, max_star + 1),
                key=lambda x: star_scores.get(x, 0),
                reverse=True
            )[:num_stars]
            
            return {
                'numbers': sorted(top_numbers),
                'stars': sorted(top_stars)
            }
        except Exception as e:
            logger.error(f"Erreur pr√©diction num√©ros/√©toiles: {e}")
            # Fallback: s√©lection al√©atoire
            import random
            return {
                'numbers': sorted(random.sample(range(1, max_number + 1), num_numbers)),
                'stars': sorted(random.sample(range(1, max_star + 1), num_stars))
            }
    
    def _get_number_scores(self, X: np.ndarray, max_number: int) -> Dict[int, float]:
        """Calcule les scores pour chaque num√©ro."""
        scores = {}
        
        for model_name, model in self.models.items():
            try:
                weight = self.model_weights.get(model_name, 1.0)
                
                # Obtenir les scores du mod√®le (√† adapter selon l'interface du mod√®le)
                if hasattr(model, 'get_number_scores'):
                    model_scores = model.get_number_scores(X)
                    for num, score in model_scores.items():
                        scores[num] = scores.get(num, 0) + score * weight
            except Exception as e:
                logger.debug(f"Impossible d'obtenir scores de {model_name}: {e}")
        
        # Normaliser les scores
        if scores:
            max_score = max(scores.values())
            if max_score > 0:
                scores = {k: v / max_score for k, v in scores.items()}
        
        return scores
    
    def _get_star_scores(self, X: np.ndarray, max_star: int) -> Dict[int, float]:
        """Calcule les scores pour chaque √©toile."""
        scores = {}
        
        for model_name, model in self.models.items():
            try:
                weight = self.model_weights.get(model_name, 1.0)
                
                if hasattr(model, 'get_star_scores'):
                    model_scores = model.get_star_scores(X)
                    for star, score in model_scores.items():
                        scores[star] = scores.get(star, 0) + score * weight
            except Exception as e:
                logger.debug(f"Impossible d'obtenir scores √©toiles de {model_name}: {e}")
        
        # Normaliser
        if scores:
            max_score = max(scores.values())
            if max_score > 0:
                scores = {k: v / max_score for k, v in scores.items()}
        
        return scores
    
    def update_weights(self, model_scores: Dict[str, float]):
        """
        Met √† jour les poids des mod√®les bas√© sur leurs performances.
        
        Args:
            model_scores: Dict {model_name: score} avec scores entre 0 et 1
        """
        if not self.auto_adjust:
            logger.info("Auto-ajustement d√©sactiv√©")
            return
        
        logger.info("üîÑ Mise √† jour des poids des mod√®les...")
        
        for model_name, score in model_scores.items():
            if model_name not in self.model_weights:
                continue
            
            old_weight = self.model_weights[model_name]
            
            # Ajuster le poids en fonction du score
            if score > 0.7:
                # Bon score: augmenter le poids
                new_weight = old_weight * 1.1
            elif score < 0.4:
                # Mauvais score: diminuer le poids
                new_weight = old_weight * 0.9
            else:
                # Score moyen: l√©g√®re augmentation
                new_weight = old_weight * 1.02
            
            # Limiter les poids entre 0.1 et 2.0
            new_weight = max(0.1, min(2.0, new_weight))
            
            self.model_weights[model_name] = new_weight
            
            logger.info(f"  {model_name}: {old_weight:.3f} ‚Üí {new_weight:.3f} (score: {score:.3f})")
            
            # Enregistrer dans l'historique
            self.model_scores[model_name].append(score)
        
        # Normaliser les poids
        self._normalize_weights()
    
    def _normalize_weights(self):
        """Normalise les poids pour qu'ils somment √† 1."""
        total = sum(self.model_weights.values())
        if total > 0:
            for model_name in self.model_weights:
                self.model_weights[model_name] /= total
    
    def save(self, output_dir: str):
        """Sauvegarde le syst√®me de fusion."""
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Sauvegarder le m√©ta-mod√®le
        if self.meta_model is not None:
            meta_model_path = output_path / "meta_model.pkl"
            with open(meta_model_path, 'wb') as f:
                pickle.dump(self.meta_model, f)
            logger.info(f"‚úÖ M√©ta-mod√®le sauvegard√©: {meta_model_path}")
        
        # Sauvegarder les poids et scores
        weights_path = output_path / "model_weights.json"
        with open(weights_path, 'w', encoding='utf-8') as f:
            json.dump({
                'weights': self.model_weights,
                'scores': {k: list(v) for k, v in self.model_scores.items()}
            }, f, indent=2)
        logger.info(f"‚úÖ Poids sauvegard√©s: {weights_path}")
    
    def load(self, input_dir: str):
        """Charge le syst√®me de fusion."""
        input_path = Path(input_dir)
        
        # Charger le m√©ta-mod√®le
        meta_model_path = input_path / "meta_model.pkl"
        if meta_model_path.exists():
            with open(meta_model_path, 'rb') as f:
                self.meta_model = pickle.load(f)
            logger.info(f"‚úÖ M√©ta-mod√®le charg√©: {meta_model_path}")
        
        # Charger les poids
        weights_path = input_path / "model_weights.json"
        if weights_path.exists():
            with open(weights_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                self.model_weights = data.get('weights', {})
                scores = data.get('scores', {})
                self.model_scores = defaultdict(list, {k: v for k, v in scores.items()})
            logger.info(f"‚úÖ Poids charg√©s: {weights_path}")


def main():
    """Fonction de test."""
    logger.info("=== Test MetaModelFusion ===")
    
    # Cr√©er une instance
    fusion = MetaModelFusion(
        fusion_method="stacking",
        meta_model_type="xgboost",
        auto_adjust=True
    )
    
    # Simuler des mod√®les (√† remplacer par de vrais mod√®les)
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.linear_model import LogisticRegression
    
    model1 = RandomForestClassifier(n_estimators=10, random_state=42)
    model2 = LogisticRegression(random_state=42)
    
    fusion.register_model("random_forest", model1, initial_weight=1.0)
    fusion.register_model("logistic", model2, initial_weight=0.8)
    
    # Donn√©es de test
    X = np.random.rand(100, 10)
    y = np.random.randint(0, 2, 100)
    
    # Entra√Æner
    fusion.fit(X, y)
    
    # Pr√©dire
    X_test = np.random.rand(10, 10)
    predictions = fusion.predict(X_test)
    logger.info(f"Pr√©dictions: {predictions}")
    
    # Mettre √† jour les poids
    fusion.update_weights({
        "random_forest": 0.75,
        "logistic": 0.85
    })
    
    logger.info("‚úÖ Test termin√©")


if __name__ == "__main__":
    main()

